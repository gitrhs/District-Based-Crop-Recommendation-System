{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 27\n",
      "Samples: 903\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('dataset/district_information.csv')\n",
    "\n",
    "# Define X and Y\n",
    "Y_column = ['crop_rank_1', 'crop_rank_2', 'crop_rank_3', 'crop_rank_4', 'crop_rank_5']\n",
    "X = df.drop(columns=Y_column)\n",
    "y = df[Y_column]\n",
    "\n",
    "print(f\"Original features: {X.shape[1]}\")\n",
    "print(f\"Samples: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVE REDUNDANT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after manual removal: 16\n"
     ]
    }
   ],
   "source": [
    "# remove obviously redundant features\n",
    "redundant = {\n",
    "    'Source',\n",
    "    'temperature_2m_min', 'temperature_2m_max',\n",
    "    'elev_min', 'elev_max',\n",
    "    'slope_min', 'slope_max',\n",
    "    'state', 'district',\n",
    "    'lat', 'lon'\n",
    "}\n",
    "\n",
    "# drop the columns\n",
    "X_reduced = X.drop(redundant, axis=1)\n",
    "print(f\"Features after manual removal: {X_reduced.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Highly correlated features to remove (correlation > 0.85):\n",
      "   - shortwave_radiation_sum\n",
      "   - slope_mean\n",
      "   - OM (%)\n"
     ]
    }
   ],
   "source": [
    "# CORRELATION-BASED REMOVAL\n",
    "def remove_correlated_features(df, threshold=0.85):\n",
    "    \"\"\"Remove highly correlated features\"\"\"\n",
    "    # Only use numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    corr_matrix = df[numeric_cols].corr().abs()\n",
    "    \n",
    "    # Find features to remove\n",
    "    upper_triangle = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    to_remove = [column for column in upper_triangle.columns \n",
    "                if any(upper_triangle[column] > threshold)]\n",
    "    \n",
    "    return to_remove, corr_matrix\n",
    "\n",
    "correlated_features, corr_matrix = remove_correlated_features(X_reduced, threshold=0.85)\n",
    "\n",
    "print(f\"ðŸ” Highly correlated features to remove (correlation > 0.85):\")\n",
    "for feature in correlated_features:\n",
    "    print(f\"   - {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after correlation removal: 13\n"
     ]
    }
   ],
   "source": [
    "# remove the highly correlated features \n",
    "X_reduced = X_reduced.drop(columns=correlated_features)\n",
    "print(f\"Features after correlation removal: {X_reduced.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODE CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['crop_type', 'Land Use']\n",
      "Final preprocessed features: 13\n"
     ]
    }
   ],
   "source": [
    "X_processed = X_reduced.copy()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_processed[col] = le.fit_transform(X_processed[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Handle missing values\n",
    "X_processed = X_processed.fillna(X_processed.median())\n",
    "\n",
    "print(f\"Final preprocessed features: {X_processed.shape[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
